# Exerc√≠cios Pr√°ticos - Apache Kafka

Este diret√≥rio cont√©m exerc√≠cios pr√°ticos para consolidar o aprendizado sobre Kafka.

## Como Usar

1. Leia o enunciado do exerc√≠cio
2. Tente resolver sozinho primeiro
3. Consulte as dicas se precisar
4. Compare com a solu√ß√£o sugerida
5. Execute e teste seu c√≥digo

## Pr√©-requisitos

- Kafka instalado e rodando (veja `docs/03-instalacao-setup.md`)
- Java 8+ ou Python 3.7+
- Conhecimento b√°sico de programa√ß√£o

---

## Exerc√≠cio 1: Hello Kafka

**N√≠vel:** Iniciante

**Objetivo:** Criar seu primeiro producer e consumer

**Tarefa:**
1. Crie um producer que envia 5 mensagens para um t√≥pico chamado "hello-kafka"
2. Crie um consumer que l√™ essas mensagens e as imprime no console
3. As mensagens devem ter o formato: "Mensagem n√∫mero X"

**Dicas:**
- Use `SimpleProducer.java` como refer√™ncia
- Lembre-se de criar o t√≥pico antes: `kafka-topics.sh --create --topic hello-kafka --partitions 1 --replication-factor 1`
- Configure `auto.offset.reset=earliest` no consumer

**O que voc√™ vai aprender:**
- Configura√ß√£o b√°sica de producer e consumer
- Envio e recebimento de mensagens
- Conceito de t√≥pico

---

## Exerc√≠cio 2: Particionamento

**N√≠vel:** Intermedi√°rio

**Objetivo:** Entender como funcionam parti√ß√µes

**Tarefa:**
1. Crie um t√≥pico com 3 parti√ß√µes: "users-topic"
2. Implemente um producer que envia mensagens com chaves (user_id)
3. Envie 30 mensagens com user_ids de 1 a 10 (3 mensagens por usu√°rio)
4. Crie um consumer e observe em quais parti√ß√µes as mensagens ca√≠ram
5. Verifique se mensagens do mesmo user_id foram para a mesma parti√ß√£o

**Dicas:**
- Use `ProducerRecord` com chave: `new ProducerRecord<>(topic, key, value)`
- Para ver as parti√ß√µes: `kafka-topics.sh --describe --topic users-topic`
- No consumer, imprima `record.partition()` junto com a chave

**O que voc√™ vai aprender:**
- Como Kafka particiona mensagens
- Import√¢ncia das chaves para ordem
- Hash partitioning

---

## Exerc√≠cio 3: Consumer Groups

**N√≠vel:** Intermedi√°rio

**Objetivo:** Trabalhar com m√∫ltiplos consumers

**Tarefa:**
1. Crie um t√≥pico "events" com 4 parti√ß√µes
2. Implemente um producer que envia 100 mensagens
3. Crie 2 consumers no mesmo grupo e observe a distribui√ß√£o
4. Adicione um terceiro consumer e veja o rebalancing
5. Pare um consumer e observe a redistribui√ß√£o

**Dicas:**
- Use o mesmo `group.id` para todos consumers do grupo
- Execute cada consumer em um terminal diferente
- Use `kafka-consumer-groups.sh --describe` para ver a distribui√ß√£o

**O que voc√™ vai aprender:**
- Consumer groups
- Rebalancing
- Paraleliza√ß√£o de consumo
- Alta disponibilidade

---

## Exerc√≠cio 4: Commit Manual de Offset

**N√≠vel:** Intermedi√°rio

**Objetivo:** Controlar quando offsets s√£o commitados

**Tarefa:**
1. Crie um consumer com commit manual desabilitado
2. Processe mensagens e fa√ßa commit apenas ap√≥s processamento bem-sucedido
3. Simule uma falha de processamento e veja que a mensagem n√£o √© perdida
4. Implemente retry logic para mensagens que falharam

**Dicas:**
- Configure `enable.auto.commit=false`
- Use `consumer.commitSync()` ap√≥s processar com sucesso
- Para simular falha, lance exce√ß√£o para mensagens espec√≠ficas

**O que voc√™ vai aprender:**
- Controle de offset
- Garantias de processamento
- At-least-once semantics
- Retry logic

---

## Exerc√≠cio 5: Producer com Callback

**N√≠vel:** Intermedi√°rio

**Objetivo:** Usar callbacks para produ√ß√£o ass√≠ncrona

**Tarefa:**
1. Implemente um producer que usa callbacks
2. Envie 1000 mensagens rapidamente
3. No callback, conte sucessos e falhas
4. Implemente retry para mensagens que falharam
5. Compare o tempo com envio s√≠ncrono

**Dicas:**
- Use `producer.send(record, callback)`
- Callback recebe `RecordMetadata` e `Exception`
- Use `AtomicInteger` para contar sucessos/falhas (thread-safe)

**O que voc√™ vai aprender:**
- Produ√ß√£o ass√≠ncrona
- Callbacks
- Performance tuning
- Error handling

---

## Exerc√≠cio 6: Dead Letter Queue

**N√≠vel:** Avan√ßado

**Objetivo:** Implementar pattern de DLQ

**Tarefa:**
1. Crie um consumer que processa mensagens
2. Se processamento falhar ap√≥s 3 tentativas, envie para DLQ
3. Implemente um consumer separado para o DLQ
4. Grave logs das mensagens que foram para DLQ

**Dicas:**
- Use um t√≥pico separado como DLQ (ex: "main-topic-dlq")
- Adicione headers com informa√ß√µes de erro
- Considere usar `ProducerRecord` com headers

**O que voc√™ vai aprender:**
- Error handling avan√ßado
- Pattern DLQ
- Resili√™ncia
- Observabilidade

---

## Exerc√≠cio 7: Serializa√ß√£o Customizada

**N√≠vel:** Avan√ßado

**Objetivo:** Trabalhar com objetos Java complexos

**Tarefa:**
1. Crie uma classe `Order` com campos: id, userId, amount, items
2. Implemente um custom serializer/deserializer para Order
3. Crie producer e consumer que trabalham com objetos Order
4. Considere usar JSON ou Avro

**Dicas:**
- Implemente `Serializer<Order>` e `Deserializer<Order>`
- Ou use bibliotecas: Jackson para JSON, Confluent Schema Registry para Avro
- Configure `value.serializer` e `value.deserializer` com suas classes

**O que voc√™ vai aprender:**
- Serializa√ß√£o customizada
- Schema evolution
- Integra√ß√£o com JSON/Avro
- Type safety

---

## Exerc√≠cio 8: Monitoramento de Consumer Lag

**N√≠vel:** Avan√ßado

**Objetivo:** Monitorar e gerenciar lag

**Tarefa:**
1. Crie um producer que envia mensagens continuamente
2. Crie um consumer "lento" que demora para processar
3. Use ferramentas para monitorar o lag
4. Implemente alertas quando lag ultrapassar threshold
5. Adicione mais consumers para reduzir lag

**Dicas:**
- Use `kafka-consumer-groups.sh --describe` para ver lag
- Ou use JMX metrics
- Simule processamento lento com `Thread.sleep()`

**O que voc√™ vai aprender:**
- Consumer lag
- Monitoramento
- Escalabilidade
- Opera√ß√µes

---

## Exerc√≠cio B√¥nus: Mini Projeto

**N√≠vel:** Avan√ßado

**Objetivo:** Integrar tudo que aprendeu

**Tarefa:**
Implemente um sistema de processamento de pedidos:

1. **Order Producer Service:**
   - Recebe pedidos via REST API
   - Publica no t√≥pico "orders"
   - Usa chave = user_id

2. **Payment Processor Service:**
   - Consome de "orders"
   - Processa pagamento (simule)
   - Publica resultado em "payment-results"
   - Usa DLQ para falhas

3. **Notification Service:**
   - Consome de "payment-results"
   - Envia notifica√ß√£o (simule)
   - Usa consumer group para escalabilidade

4. **Monitoring Dashboard:**
   - Monitora lag de todos consumers
   - Conta mensagens processadas
   - Rastreia erros

**O que voc√™ vai aprender:**
- Arquitetura event-driven
- Microservi√ßos
- Integra√ß√£o de sistemas
- Pr√°ticas do mundo real

---

## Recursos Adicionais

- Consulte `/examples` para c√≥digo de refer√™ncia
- Leia `/docs` para conceitos te√≥ricos
- Use `/resources/links-uteis.md` para materiais extras

## D√∫vidas?

- Revise a documenta√ß√£o em `/docs`
- Consulte os exemplos em `/examples`
- Pratique, pratique, pratique!

Boa sorte! üöÄ
